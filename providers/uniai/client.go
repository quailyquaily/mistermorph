package uniai

import (
	"context"
	"encoding/json"
	"fmt"
	"strconv"
	"strings"
	"time"

	"github.com/lyricat/goutils/structs"
	"github.com/quailyquaily/mistermorph/llm"
	uniaiapi "github.com/quailyquaily/uniai"
	uniaichat "github.com/quailyquaily/uniai/chat"
)

type Config struct {
	Provider string
	Endpoint string
	APIKey   string
	Model    string

	RequestTimeout time.Duration

	ToolsEmulationMode  string
	AzureAPIKey         string
	AzureEndpoint       string
	AzureDeployment     string
	AwsKey              string
	AwsSecret           string
	AwsRegion           string
	AwsBedrockModelArn  string
	CloudflareAccountID string
	CloudflareAPIToken  string
	CloudflareAPIBase   string

	Debug bool
}

type Client struct {
	provider           string
	requestTimeout     time.Duration
	toolsEmulationMode uniaiapi.ToolsEmulationMode
	client             *uniaiapi.Client
	debugFn            func(label, payload string)
}

func New(cfg Config) *Client {
	provider := strings.ToLower(strings.TrimSpace(cfg.Provider))

	openAIBase := normalizeOpenAIBase(cfg.Endpoint)
	openAIKey := strings.TrimSpace(cfg.APIKey)

	azureAPIKey := firstNonEmpty(cfg.AzureAPIKey, cfg.APIKey)
	azureEndpoint := firstNonEmpty(cfg.AzureEndpoint, cfg.Endpoint)
	azureDeployment := firstNonEmpty(cfg.AzureDeployment, cfg.Model)

	anthropicKey := strings.TrimSpace(cfg.APIKey)
	anthropicModel := strings.TrimSpace(cfg.Model)

	geminiKey := strings.TrimSpace(cfg.APIKey)
	geminiBase := strings.TrimSpace(cfg.Endpoint)

	uCfg := uniaiapi.Config{
		Provider:            provider,
		OpenAIAPIKey:        openAIKey,
		OpenAIAPIBase:       openAIBase,
		OpenAIModel:         strings.TrimSpace(cfg.Model),
		AzureOpenAIAPIKey:   strings.TrimSpace(azureAPIKey),
		AzureOpenAIEndpoint: strings.TrimSpace(azureEndpoint),
		AzureOpenAIModel:    strings.TrimSpace(azureDeployment),
		AnthropicAPIKey:     strings.TrimSpace(anthropicKey),
		AnthropicModel:      strings.TrimSpace(anthropicModel),
		AwsKey:              strings.TrimSpace(cfg.AwsKey),
		AwsSecret:           strings.TrimSpace(cfg.AwsSecret),
		AwsRegion:           strings.TrimSpace(cfg.AwsRegion),
		AwsBedrockModelArn:  strings.TrimSpace(cfg.AwsBedrockModelArn),
		CloudflareAccountID: strings.TrimSpace(cfg.CloudflareAccountID),
		CloudflareAPIToken:  strings.TrimSpace(cfg.CloudflareAPIToken),
		CloudflareAPIBase:   strings.TrimSpace(cfg.CloudflareAPIBase),
		GeminiAPIKey:        strings.TrimSpace(geminiKey),
		GeminiAPIBase:       strings.TrimSpace(geminiBase),

		Debug: cfg.Debug,
	}

	return &Client{
		provider:           provider,
		requestTimeout:     cfg.RequestTimeout,
		toolsEmulationMode: normalizeToolsEmulationMode(cfg.ToolsEmulationMode),
		client:             uniaiapi.New(uCfg),
	}
}

func (c *Client) Chat(ctx context.Context, req llm.Request) (llm.Result, error) {
	start := time.Now()
	if c.requestTimeout > 0 {
		var cancel context.CancelFunc
		ctx, cancel = context.WithTimeout(ctx, c.requestTimeout)
		defer cancel()
	}

	opts := buildChatOptions(req, c.provider, req.ForceJSON, c.toolsEmulationMode, c.debugFn)
	resp, err := c.client.Chat(ctx, opts...)
	if err != nil {
		c.emitChatError(err, req.ForceJSON, 1)
	}
	if err != nil && req.ForceJSON && shouldRetryWithoutResponseFormat(err) {
		opts = buildChatOptions(req, c.provider, false, c.toolsEmulationMode, c.debugFn)
		resp, err = c.client.Chat(ctx, opts...)
		if err != nil {
			c.emitChatError(err, false, 2)
		}
	}
	if err != nil {
		return llm.Result{}, err
	}
	if resp == nil {
		err = fmt.Errorf("uniai: empty response")
		c.emitChatError(err, req.ForceJSON, 0)
		return llm.Result{}, err
	}

	toolCalls := toLLMToolCalls(resp.ToolCalls)

	return llm.Result{
		Text:      resp.Text,
		ToolCalls: toolCalls,
		Usage: llm.Usage{
			InputTokens:  resp.Usage.InputTokens,
			OutputTokens: resp.Usage.OutputTokens,
			TotalTokens:  resp.Usage.TotalTokens,
		},
		Duration: time.Since(start),
	}, nil
}

func buildChatOptions(req llm.Request, provider string, forceJSON bool, toolsEmulationMode uniaiapi.ToolsEmulationMode, debugFn func(label, payload string)) []uniaiapi.ChatOption {
	msgs := make([]uniaiapi.Message, len(req.Messages))
	for i, m := range req.Messages {
		msg := uniaiapi.Message{Role: m.Role, Content: m.Content}
		if strings.TrimSpace(m.ToolCallID) != "" {
			msg.ToolCallID = m.ToolCallID
		}
		if len(m.ToolCalls) > 0 {
			msg.ToolCalls = toUniaiToolCallsFromLLM(m.ToolCalls)
		}
		msgs[i] = msg
	}

	opts := []uniaiapi.ChatOption{uniaiapi.WithReplaceMessages(msgs...)}
	if provider != "" {
		opts = append(opts, uniaiapi.WithProvider(provider))
	}
	if strings.TrimSpace(req.Model) != "" {
		opts = append(opts, uniaiapi.WithModel(strings.TrimSpace(req.Model)))
	}

	if len(req.Tools) > 0 {
		tools := make([]uniaiapi.Tool, 0, len(req.Tools))
		for _, t := range req.Tools {
			name := strings.TrimSpace(t.Name)
			if name == "" {
				continue
			}
			tools = append(tools, uniaiapi.FunctionTool(
				name,
				strings.TrimSpace(t.Description),
				[]byte(t.ParametersJSON),
			))
		}
		if len(tools) > 0 {
			opts = append(opts, uniaiapi.WithTools(tools))
			opts = append(opts, uniaiapi.WithToolChoice(uniaiapi.ToolChoiceAuto()))
			if toolsEmulationMode != "" && toolsEmulationMode != uniaiapi.ToolsEmulationOff {
				opts = append(opts, uniaiapi.WithToolsEmulationMode(toolsEmulationMode))
			}
		}
	}

	appliedTemperature := false
	if req.Parameters != nil {
		if v, ok := floatFromAny(req.Parameters["temperature"]); ok {
			opts = append(opts, uniaiapi.WithTemperature(v))
			appliedTemperature = true
		}
		if v, ok := floatFromAny(req.Parameters["top_p"]); ok {
			opts = append(opts, uniaiapi.WithTopP(v))
		}
		if v, ok := intFromAny(req.Parameters["max_tokens"]); ok && v > 0 {
			opts = append(opts, uniaiapi.WithMaxTokens(v))
		}
		if v, ok := stringSliceFromAny(req.Parameters["stop"]); ok && len(v) > 0 {
			opts = append(opts, uniaiapi.WithStopWords(v...))
		}
		if v, ok := floatFromAny(req.Parameters["presence_penalty"]); ok {
			opts = append(opts, uniaiapi.WithPresencePenalty(v))
		}
		if v, ok := floatFromAny(req.Parameters["frequency_penalty"]); ok {
			opts = append(opts, uniaiapi.WithFrequencyPenalty(v))
		}
		if v, ok := req.Parameters["user"].(string); ok && strings.TrimSpace(v) != "" {
			opts = append(opts, uniaiapi.WithUser(strings.TrimSpace(v)))
		}
	}
	if !appliedTemperature {
		opts = append(opts, uniaiapi.WithTemperature(0))
	}

	if forceJSON {
		opts = append(opts, uniaichat.WithOpenAIOptions(structs.JSONMap{
			"response_format": "json_object",
		}))
	}

	if debugFn != nil {
		opts = append(opts, uniaiapi.WithDebugFn(debugFn))
	}

	return opts
}

func normalizeToolsEmulationMode(mode string) uniaiapi.ToolsEmulationMode {
	switch strings.ToLower(strings.TrimSpace(mode)) {
	case "force":
		return uniaiapi.ToolsEmulationForce
	case "fallback":
		return uniaiapi.ToolsEmulationFallback
	default:
		return uniaiapi.ToolsEmulationOff
	}
}

func (c *Client) SetDebugFn(fn func(label, payload string)) {
	c.debugFn = fn
}

func (c *Client) emitChatError(err error, forceJSON bool, attempt int) {
	if err == nil || c == nil || c.debugFn == nil {
		return
	}

	provider := strings.TrimSpace(c.provider)
	if provider == "" {
		provider = "openai"
	}
	label := provider + ".chat.error"

	payload := map[string]any{
		"provider": provider,
		"error":    err.Error(),
	}
	if attempt > 0 {
		payload["attempt"] = attempt
	}
	if forceJSON {
		payload["force_json"] = true
	}

	data, marshalErr := json.Marshal(payload)
	if marshalErr != nil {
		c.debugFn(label, err.Error())
		return
	}
	c.debugFn(label, string(data))
}

func toLLMToolCalls(calls []uniaiapi.ToolCall) []llm.ToolCall {
	if len(calls) == 0 {
		return nil
	}
	out := make([]llm.ToolCall, 0, len(calls))
	for _, call := range calls {
		name := strings.TrimSpace(call.Function.Name)
		if name == "" {
			continue
		}
		params := map[string]any{}
		if strings.TrimSpace(call.Function.Arguments) != "" {
			if err := json.Unmarshal([]byte(call.Function.Arguments), &params); err != nil {
				params = map[string]any{"_raw": call.Function.Arguments}
			}
		}
		out = append(out, llm.ToolCall{
			ID:               call.ID,
			Type:             call.Type,
			Name:             name,
			Arguments:        params,
			RawArguments:     call.Function.Arguments,
			ThoughtSignature: call.ThoughtSignature,
		})
	}
	if len(out) == 0 {
		return nil
	}
	return out
}

func toUniaiToolCallsFromLLM(calls []llm.ToolCall) []uniaiapi.ToolCall {
	if len(calls) == 0 {
		return nil
	}
	out := make([]uniaiapi.ToolCall, 0, len(calls))
	for _, call := range calls {
		name := strings.TrimSpace(call.Name)
		if name == "" {
			continue
		}
		args := "{}"
		if strings.TrimSpace(call.RawArguments) != "" {
			args = call.RawArguments
		} else if call.Arguments != nil {
			if data, err := json.Marshal(call.Arguments); err == nil {
				args = string(data)
			}
		}
		callType := call.Type
		if strings.TrimSpace(callType) == "" {
			callType = "function"
		}
		out = append(out, uniaiapi.ToolCall{
			ID:               call.ID,
			Type:             callType,
			ThoughtSignature: call.ThoughtSignature,
			Function: uniaiapi.ToolCallFunction{
				Name:      name,
				Arguments: args,
			},
		})
	}
	if len(out) == 0 {
		return nil
	}
	return out
}

func shouldRetryWithoutResponseFormat(err error) bool {
	if err == nil {
		return false
	}
	msg := strings.ToLower(err.Error())
	return strings.Contains(msg, "response_format") || strings.Contains(msg, "response format")
}

func normalizeOpenAIBase(endpoint string) string {
	endpoint = strings.TrimSpace(endpoint)
	if endpoint == "" {
		return ""
	}
	endpoint = strings.TrimRight(endpoint, "/")
	if strings.HasSuffix(endpoint, "/v1") || strings.Contains(endpoint, "/v1/") {
		return endpoint
	}
	return endpoint + "/v1"
}

func firstNonEmpty(values ...string) string {
	for _, v := range values {
		if strings.TrimSpace(v) != "" {
			return v
		}
	}
	return ""
}

func floatFromAny(value any) (float64, bool) {
	switch v := value.(type) {
	case float64:
		return v, true
	case float32:
		return float64(v), true
	case int:
		return float64(v), true
	case int64:
		return float64(v), true
	case json.Number:
		if val, err := v.Float64(); err == nil {
			return val, true
		}
	case string:
		if val, err := strconv.ParseFloat(strings.TrimSpace(v), 64); err == nil {
			return val, true
		}
	}
	return 0, false
}

func intFromAny(value any) (int, bool) {
	switch v := value.(type) {
	case int:
		return v, true
	case int64:
		return int(v), true
	case float64:
		return int(v), true
	case json.Number:
		if val, err := v.Int64(); err == nil {
			return int(val), true
		}
	case string:
		if val, err := strconv.Atoi(strings.TrimSpace(v)); err == nil {
			return val, true
		}
	}
	return 0, false
}

func stringSliceFromAny(value any) ([]string, bool) {
	switch v := value.(type) {
	case []string:
		return append([]string{}, v...), true
	case []any:
		out := make([]string, 0, len(v))
		for _, item := range v {
			s, ok := item.(string)
			if !ok {
				return nil, false
			}
			out = append(out, s)
		}
		return out, true
	case string:
		if strings.TrimSpace(v) == "" {
			return nil, false
		}
		return []string{strings.TrimSpace(v)}, true
	default:
		return nil, false
	}
}
